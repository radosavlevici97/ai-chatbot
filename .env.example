# ╔══════════════════════════════════════════════════════════════╗
# ║  AI Chatbot — Complete Environment Configuration            ║
# ║  Copy to .env and fill in required values                   ║
# ║  Variables marked [REQUIRED] must be set                    ║
# ║  Variables marked [OPTIONAL] have sensible defaults         ║
# ╚══════════════════════════════════════════════════════════════╝

# ── Application ────────────────────────────────────────────────

# [OPTIONAL] Environment mode — controls log level, cookie security
NODE_ENV=development

# [OPTIONAL] Backend server port
PORT=8000

# ── Authentication ─────────────────────────────────────────────

# [REQUIRED] JWT signing secret — generate with: openssl rand -hex 32
# Must be at least 32 characters. NEVER commit this value.
JWT_SECRET=

# [OPTIONAL] Access token expiry in minutes (default: 60)
JWT_ACCESS_EXPIRE_MINUTES=60

# [OPTIONAL] Refresh token expiry in days (default: 7)
JWT_REFRESH_EXPIRE_DAYS=7

# [OPTIONAL] Cookie domain — leave empty for localhost
# Set to your Railway domain in production (e.g., .railway.app)
# COOKIE_DOMAIN=

# [OPTIONAL] Cookie Secure flag — true in production, false for localhost
COOKIE_SECURE=false

# ── LLM Provider (Chat) ───────────────────────────────────────

# [OPTIONAL] Primary chat provider: gemini | openrouter | ollama
LLM_PROVIDER=gemini

# [REQUIRED] Google AI Studio API key — https://aistudio.google.com/apikey
GEMINI_API_KEY=

# [OPTIONAL] Gemini chat model
GEMINI_MODEL=gemini-2.5-flash

# ── Embedding Provider ─────────────────────────────────────────

# [OPTIONAL] Embedding provider — always gemini (for showcase)
EMBEDDING_PROVIDER=gemini

# [OPTIONAL] Gemini embedding model
GEMINI_EMBEDDING_MODEL=text-embedding-004

# ── Fallback LLM (OpenRouter) ─────────────────────────────────

# [OPTIONAL] OpenRouter API key — enables fallback when Gemini rate-limits
# Get a free key at: https://openrouter.ai/keys
# OPENROUTER_API_KEY=

# [OPTIONAL] OpenRouter model — free models have :free suffix
OPENROUTER_MODEL=meta-llama/llama-3.1-8b-instruct:free

# ── Database ───────────────────────────────────────────────────

# [OPTIONAL] SQLite database file path
# Local dev: ./data/chatbot.db
# Railway with Volume: /data/chatbot.db
DATABASE_PATH=./data/chatbot.db

# ── CORS ───────────────────────────────────────────────────────

# [REQUIRED in production] Frontend URL for CORS origin
# Supports comma-separated values: https://app.vercel.app,https://custom.com
FRONTEND_URL=http://localhost:3000

# [OPTIONAL] Allow Vercel preview deployment URLs (*.vercel.app)
ALLOW_VERCEL_PREVIEWS=false

# ── File Storage ───────────────────────────────────────────────

# [OPTIONAL] Storage backend: local | r2
STORAGE_TYPE=local

# [OPTIONAL] Local upload directory
# Local dev: ./data/uploads
# Railway with Volume: /data/uploads
UPLOAD_DIR=./data/uploads

# [OPTIONAL] Maximum upload file size in MB
UPLOAD_MAX_SIZE_MB=25

# ── Cloudflare R2 (if STORAGE_TYPE=r2) ────────────────────────

# [REQUIRED if STORAGE_TYPE=r2] Cloudflare account ID
# R2_ACCOUNT_ID=

# [REQUIRED if STORAGE_TYPE=r2] R2 API access key
# R2_ACCESS_KEY=

# [REQUIRED if STORAGE_TYPE=r2] R2 API secret key
# R2_SECRET_KEY=

# [REQUIRED if STORAGE_TYPE=r2] R2 bucket name
# R2_BUCKET=

# ── Rate Limiting ──────────────────────────────────────────────

# [OPTIONAL] Auth endpoints: max requests per minute per IP
RATE_LIMIT_AUTH_PER_MINUTE=10

# [OPTIONAL] Chat endpoint: max messages per minute per user
RATE_LIMIT_CHAT_PER_MINUTE=30

# [OPTIONAL] Upload endpoint: max uploads per hour per user
RATE_LIMIT_UPLOAD_PER_HOUR=20

# ── Frontend (set in Vercel dashboard or .env.local) ───────────

# [REQUIRED] Backend API URL — set in Vercel dashboard
# NEXT_PUBLIC_API_URL=https://your-backend.railway.app/api/v1
